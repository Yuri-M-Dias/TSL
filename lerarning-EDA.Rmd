---
title: "Learning time series!"
output: html_notebook
---

# Learning Time Series

```{r}
library(data.table)
library(tidyverse)

data = fread('./Data/daily-total-female-births.csv')

slw = as.data.table(
  matrix(data$Births, ncol = 5,  byrow = TRUE),
  stringsAsFactors = FALSE
)

slw = slw[,.(nextValue = V5), by = list(V1,V2,V3,V4)]
```

Great!

```{r}
library(keras)

model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 64, activation = 'relu', input_shape = 4) %>% 
  layer_dense(units = 32, activation = 'relu') %>% 
  layer_dense(units = 6, activation = 'relu') %>% 
  layer_dense(units = 1)

model %>% compile(
  loss = 'mse',
  optimizer = optimizer_adam(),
  metrics = c('mae')
)
summary(model)
```

```{r, echo=F,eval=F}
slwm = as.matrix(slw)
slwm.train = slwm[1:58,]
slwm.test = slwm[59:73,]

# The patience parameter is the amount of epochs to check for improvement.
early_stop <- callback_early_stopping(
  monitor = "val_loss", patience = 20
)

history <- model %>% fit(
  x = slwm.train[,1:4],
  y = slwm.train[,5],
  batch_size = 2,
  epochs = 2000,
  callbacks = list(early_stop),
  verbose = 2
)

```

```{r}
model %>% evaluate(x = slwm.train[,1:4], y = slwm.train[,5])
model %>% evaluate(x = slwm.test[,1:4], y = slwm.test[,5])

predictions = model %>% predict_on_batch(slwm.test[,1:4])
preds = data.table(real = slwm.test[,5], pred = predictions)
```

```{r}
ggplot(
  preds,
  aes(x = as.numeric(row.names(preds)))
) +
  geom_point(aes(y = real), color = 'green') +
  geom_point(aes(y = pred.V1), color = 'red')

```


